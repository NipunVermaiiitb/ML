import pandas as pd
import numpy as np
from sklearn.linear_model import LassoCV
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor

# ================== LOAD TRAIN DATA ==================
train = pd.read_csv('/kaggle/input/Medical-Equipments-Cost-Prediction-Challenge/train.csv')
target_col = 'Transport_Cost'

# ================== COMPUTE DAYS_BETWEEN_ORDER_DELIVERY ==================
train['Order_Placed_Date'] = pd.to_datetime(train['Order_Placed_Date'], format='%m/%d/%y', errors='coerce')
train['Delivery_Date'] = pd.to_datetime(train['Delivery_Date'], format='%m/%d/%y', errors='coerce')
train['Days_Between_Order_Delivery'] = (train['Delivery_Date'] - train['Order_Placed_Date']).dt.days

# Keep only rows with valid Transport_Cost (no negatives)
train = train[train[target_col] >= 0]

# Replace negative or missing Days_Between_Order_Delivery with median
median_days = train['Days_Between_Order_Delivery'].median()
train.loc[train['Days_Between_Order_Delivery'] < 0, 'Days_Between_Order_Delivery'] = median_days
train['Days_Between_Order_Delivery'] = train['Days_Between_Order_Delivery'].fillna(median_days).astype(int)
# ================== DROP UNNECESSARY COLUMNS ==================
drop_cols = ['Hospital_Id', 'Hospital_Location', 'Order_Placed_Date', 'Delivery_Date', 'Supplier_Name']
train = train.drop(columns=drop_cols, errors='ignore')

# ================== SEPARATE FEATURES AND TARGET ==================
cols_to_drop = [
    "Equipment_Width",
    "Hospital_Info",
    "Fragile_Equipment",
    "Days_Between_Order_Delivery",
    "Rural_Hospital"
]

# Drop the columns
X = train.drop(columns=[target_col])
y = train[target_col]

# ================== IMPUTATION ==================
numerical_cols = X.select_dtypes(include=np.number).columns.tolist()
categorical_cols = X.select_dtypes(exclude=np.number).columns.tolist()
# print(X[categorical_cols].head(20))

num_imputer = SimpleImputer(strategy='median')
cat_imputer = SimpleImputer(strategy='most_frequent')
X[numerical_cols] = num_imputer.fit_transform(X[numerical_cols])
X[categorical_cols] = cat_imputer.fit_transform(X[categorical_cols])

# ================== OUTLIER REMOVAL (NO SCALER) ==================
Q1 = X[numerical_cols].quantile(0.25)
Q3 = X[numerical_cols].quantile(0.75)
IQR = Q3 - Q1
lower_bounds = Q1 - 0.7 * IQR
upper_bounds = Q3 + 2.1 * IQR

mask_no_outliers = ~((X[numerical_cols] < lower_bounds) | (X[numerical_cols] > upper_bounds)).any(axis=1)

# Filter y outliers using wide IQR method
Q1_y, Q3_y = y.quantile(0.10), y.quantile(0.90)
IQR_y = Q3_y - Q1_y
lower_y = Q1_y - 50 * IQR_y
upper_y = Q3_y + 125 * IQR_y
mask_y = (y >= lower_y) & (y <= upper_y)

mask = mask_no_outliers & mask_y
X = X[mask]
y = y[mask]

print(f"After outlier removal (no scaling): {len(y)} rows kept")
# ================== TARGET ENCODING ==================
print("\nApplying target encoding...")

target_encodings = {}
global_mean = y.mean()

for col in categorical_cols:
    means = y.groupby(X[col]).mean()
    target_encodings[col] = means
    X[col] = X[col].map(means)
    X[col] = X[col].fillna(global_mean)

print("Target encoding applied to training data.")

# # ================== LABEL ENCODING ==================
# onehot_cols = [
#     'Equipment_Type',
#     'CrossBorder_Shipping',
#     'Urgent_Shipping',
#     'Installation_Service',
#     'Transport_Method',
#     'Fragile_Equipment',
#     'Rural_Hospital'
# ]

# # Columns that are ordinal → label encoding
# # For example, Hospital_Info: Working Class < Wealthy
# label_cols = ['Hospital_Info']

# # ================= One-Hot Encoding =================
# X = pd.get_dummies(X, columns=onehot_cols, drop_first=True)

# # ================= Label Encoding =================
# label_encoders = {}
# for col in label_cols:
#     le = LabelEncoder()
#     X[col] = le.fit_transform(X[col].astype(str))
#     label_encoders[col] = le

# Check results
# print(X.head())

# ================== LASSO REGRESSION (NO SCALER) ==================
lasso_pipeline = Pipeline([
    ('lasso', LassoCV(
        alphas=np.logspace(-4, 3, 100),
        cv=5,
        max_iter=10000,
        random_state=42
    ))
    # ('lasso', RidgeCV(
    #     alphas=np.logspace(-4, 4, 100),
    #     cv=5
    # ))
    # ('lasso', ElasticNetCV(
    #     l1_ratio=np.linspace(0.1, 1.0, 10),
    #     alphas=np.logspace(-4, 3, 100),
    #     cv=5,
    #     max_iter=1000000,
    #     random_state=42
    # ))

    # ('lasso', RandomForestRegressor(
    #     n_estimators=300,
    #     max_depth=None,
    #     min_samples_split=2,
    #     min_samples_leaf=1,
    #     n_jobs=-1,
    #     random_state=42
    # ))

    # ('lasso', XGBRegressor(
    #     n_estimators=500,
    #     learning_rate=0.05,
    #     max_depth=6,
    #     subsample=0.8,
    #     colsample_bytree=0.8,
    #     random_state=42,
    #     n_jobs=-1
    # ))
])

# ================== K-FOLD VALIDATION ==================
kf = KFold(n_splits=2, shuffle=True, random_state=42)
rmse_list, r2_list, adj_r2_list = [], [], []
# scaler1 = StandardScaler()
# X_scaled = scaler1.fit_transform(X)
# X = pd.DataFrame(X_scaled, columns = X.columns)
# scaler2 = StandardScaler()
# y_scaled = scaler2.fit_transform(y.values.reshape(-1, 1))
# y = pd.DataFrame(y_scaled)
n = len(X)
p = X.shape[1]

for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    lasso_pipeline.fit(X_train, y_train)
    y_val_pred = lasso_pipeline.predict(X_val)

    rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))
    r2 = r2_score(y_val, y_val_pred)
    
    n_val = len(y_val)
    adj_r2 = 1 - (1 - r2) * ((n_val - 1) / (n_val - p - 1))

    rmse_list.append(rmse)
    r2_list.append(r2)
    adj_r2_list.append(adj_r2)

    print(f"Fold {fold}: RMSE = {rmse:.3f}, R² = {r2:.3f}, Adjusted R² = {adj_r2:.3f}")

print(f"\nAverage RMSE: {np.mean(rmse_list):.3f}")
print(f"Average R²: {np.mean(r2_list):.3f}")
print(f"Average Adjusted R²: {np.mean(adj_r2_list):.3f}")

# Best alpha from LassoCV
best_alpha = lasso_pipeline.named_steps['lasso'].alpha_
print(f"\nBest alpha selected by LassoCV: {best_alpha:.6f}")

# ================== FINAL TRAIN ON FULL DATA ==================
lasso_pipeline.fit(X, y)
# Get the trained Lasso model from inside the pipeline
lasso_model = lasso_pipeline.named_steps['lasso']

# Get feature names (from your original X)
feature_names = X.columns

# Combine into a DataFrame for readability
coef_df = pd.DataFrame({
    'Feature': feature_names,
    'Coefficient': lasso_model.coef_
}).sort_values(by='Coefficient', key=abs, ascending=False)

print(coef_df)



# ================== LOAD TEST SET ==================
test = pd.read_csv('/kaggle/input/Medical-Equipments-Cost-Prediction-Challenge/test.csv')
hospital_ids = test['Hospital_Id'].copy()

test['Order_Placed_Date'] = pd.to_datetime(test['Order_Placed_Date'], format='%m/%d/%y', errors='coerce')
test['Delivery_Date'] = pd.to_datetime(test['Delivery_Date'], format='%m/%d/%y', errors='coerce')
test['Days_Between_Order_Delivery'] = (test['Delivery_Date'] - test['Order_Placed_Date']).dt.days

test.loc[test['Days_Between_Order_Delivery'] < 0, 'Days_Between_Order_Delivery'] = median_days
test['Days_Between_Order_Delivery'] = test['Days_Between_Order_Delivery'].fillna(median_days).astype(int)

test = test.drop(columns=drop_cols, errors='ignore')

test[numerical_cols] = num_imputer.transform(test[numerical_cols])
test[categorical_cols] = cat_imputer.transform(test[categorical_cols])

# Apply target encoding to test set using training means
for col in categorical_cols:
    means = target_encodings[col]
    test[col] = test[col].map(means)
    test[col] = test[col].fillna(global_mean)

# Ensure test has same columns as train
test = test.reindex(columns=X.columns, fill_value=0)

# ================== PREDICTION ==================
y_pred_test = lasso_pipeline.predict(test)
pred_df = pd.DataFrame({
    'Hospital_Id': hospital_ids,
    'Transport_Cost': y_pred_test
})

print("\n===== Sample Predictions =====")
print(pred_df.head())
pred_df.to_csv('submission.csv', index=False)
print(f"\nSubmission file created with {len(pred_df)} predictions.")
